# Moodle RAG Chatbot

Интеллектуальный чат-бот для работы с документацией Moodle, построенный на архитектуре RAG (Retrieval-Augmented Generation) с использованием LangChain и Ollama.

## Что это такое

Moodle RAG Chatbot — это интеллектуальный помощник для работы с документацией Moodle. Система позволяет задавать вопросы на русском языке и получать точные ответы, основанные на официальной документации Moodle.

**Для чего нужен:**
- Обучение работе с Moodle
- Техническая поддержка
- Быстрый поиск информации в документации
- Получение пошаговых инструкций

## Особенности

- **Семантический поиск** в документации Moodle с помощью ChromaDB
- **Локальная LLM модель** (Qwen2.5:7b) через Ollama для генерации ответов
- **Кросс-язычный поиск** (русские запросы → английская документация с AI переводчиком)
- **База знаний**: Документация Moodle в векторном формате (7121 документ)
- **REST API** для интеграции
- **Память сессий** для контекстных диалогов
- **LangChain архитектура** для упрощения разработки
- **Оригинальные URL** из официальной документации Moodle
- **Детальные инструкции** с пошаговыми руководствами

## Предварительные требования

- Python 3.11 или выше
- Минимум 8GB RAM
- 10GB свободного места на диске
- Интернет-соединение для загрузки моделей
- Docker (опционально, для контейнеризованной установки)

## Быстрый старт

### 1. Клонирование и установка

```bash
git clone <repository-url>
cd moodle-rag-bot
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# или
.venv\Scripts\activate  # Windows

pip install poetry
poetry install
```

### 2. Установка Ollama

```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Запуск сервиса
brew services start ollama  # macOS
# или
ollama serve  # Linux
```

### 3. Загрузка LLM модели

```bash
# Скачивание Qwen2.5:7b модели
ollama pull qwen2.5:7b
```

### Альтернативная установка через Docker

Если вы предпочитаете использовать Docker:

```bash
# Клонирование репозитория
git clone <repository-url>
cd moodle-rag-bot

# Запуск с Docker Compose (включает Ollama)
docker-compose up -d

# Или сборка и запуск вручную
docker build -t moodle-rag-bot .
docker run -p 8000:8000 moodle-rag-bot
```

**Примечание**: При использовании Docker убедитесь, что Ollama запущен отдельно или используйте docker-compose.yml, который включает Ollama сервис.

### 4. Подготовка данных (если нужно)

```bash
# Парсинг XML файлов документации
python scripts/parse_export_xml.py

# Разбиение на чанки
python scripts/chunk_docs.py

# Загрузка в векторную базу
python scripts/ingest_chroma.py
```

### 5. Запуск API

```bash
python run_api.py
```

API будет доступен по адресу: http://localhost:8000

### 6. Тестирование

```bash
# Тест на русском (с правильным отображением Unicode)
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{"session_id": "test", "message": "Как создать новый курс в Moodle?"}' | \
  python -c "import sys, json; data=json.load(sys.stdin); print(json.dumps(data, ensure_ascii=False, indent=2))"

# Проверка здоровья системы
curl http://localhost:8000/api/v1/health

# Пример ответа с источниками и ссылками:
# {
#   "answer": "1. **Создание нового пустого курса**\n   - Войдите в систему Moodle с аккаунтом администратора...",
#   "sources": [
#     {
#       "title": "Create a course",
#       "url": "https://docs.moodle.org/403/en/Create_a_course",
#       "chunk_id": "chunk_0",
#       "score": 1.0
#     }
#   ],
#   "session_id": "test"
# }
```

## Как использовать

### Примеры вопросов

Система может отвечать на различные вопросы о Moodle:

**Создание и управление курсами:**
- "Как создать новый курс в Moodle?"
- "Как добавить пользователей в курс?"
- "Как настроить резервное копирование курса?"

**Система оценок:**
- "Как настроить систему оценок в Moodle?"
- "Как создать рубрики для оценивания?"
- "Как экспортировать оценки?"

**Пользователи и права:**
- "Как просмотреть журналы активности пользователей?"
- "Как настроить роли пользователей?"
- "Как управлять зачислением студентов?"

**Активности и ресурсы:**
- "Как создать тест в Moodle?"
- "Как добавить файлы в курс?"
- "Как настроить форум?"

### Особенности работы

- **Многоязычность**: Задавайте вопросы на русском языке
- **Автоматический перевод**: Система переводит запросы в английский
- **Источники**: Каждый ответ содержит ссылки на официальную документацию
- **Контекст**: Система помнит предыдущие вопросы в рамках сессии
- **Точность**: Ответы основаны на актуальной документации Moodle

### Примеры использования

**Запрос:**
```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{"session_id": "user123", "message": "Как создать новый курс в Moodle?"}'
```

**Ответ:**
```json
{
  "answer": "Для создания нового курса в Moodle выполните следующие шаги:\n1. Войдите в систему как администратор...",
  "sources": [
    {
      "title": "Create a course",
      "url": "https://docs.moodle.org/403/en/Create_a_course",
      "chunk_id": "chunk_0",
      "score": 1.0
    }
  ],
  "session_id": "user123"
}
```

## Архитектура

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   FastAPI       │    │   ChromaDB      │    │   Ollama        │
│   REST API      │◄──►│   Vector DB     │◄──►│   Qwen2.5:7b    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   LangChain     │    │   HuggingFace   │    │   LangChain     │
│   Pipeline      │    │   Embeddings    │    │   LLM           │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

## Конфигурация

Основные настройки в `app/core/config.py`:

- `llm_model_name`: Название модели Ollama (qwen2.5:7b)
- `embedding_model`: Модель для эмбеддингов (all-MiniLM-L6-v2)
- `top_k`: Количество релевантных документов (5)
- `llm_temperature`: Температура генерации (0.3)
- `llm_top_p`: Top-p параметр (0.9)

## API Endpoints

### POST /api/v1/chat
Основной эндпоинт для чата.

**Запрос:**
```json
{
  "session_id": "unique_session_id",
  "message": "Ваш вопрос"
}
```

**Ответ:**
```json
{
  "answer": "Ответ системы",
  "sources": [
    {
      "title": "Название документа",
      "url": "https://docs.moodle.org/403/en/Document_Name",
      "chunk_id": "ID чанка",
      "score": 0.85
    }
  ],
  "session_id": "unique_session_id"
}
```

### GET /api/v1/health
Проверка состояния системы.

## Производительность

- **Время ответа**: ~3-5 секунд
- **Размер LLM модели**: ~4.7GB (Qwen2.5:7b)
- **Поддерживаемые языки**: Английский, русский (с AI переводчиком)
- **Архитектура**: LangChain + Ollama
- **База знаний**: 7121 документ в ChromaDB
- **Максимум токенов**: 4096 для полных ответов

## Требования

- Python 3.11+
- 8GB RAM (рекомендуется)
- 10GB свободного места на диске
- Ollama

## Структура проекта

```
moodle-rag-bot/
├── app/
│   ├── api/           # FastAPI маршруты
│   ├── core/          # Конфигурация и логирование
│   ├── rag/           # RAG компоненты (LLM, Retriever, Pipeline, Prompts)
│   └── schemas.py     # Pydantic схемы
├── data/              # Данные и векторная база
├── models/            # LLM модели
├── scripts/           # Скрипты для обработки данных
└── tests/             # Тесты
```

## Технологический стек

- **LangChain** — основной фреймворк для RAG
- **Ollama** — локальный запуск LLM моделей
- **Qwen2.5:7b** — языковая модель для генерации ответов
- **ChromaDB** — векторное хранилище
- **HuggingFace Embeddings** — модель для эмбеддингов (all-MiniLM-L6-v2)
- **HuggingFace Transformers** — AI переводчик (MarianMT)
- **FastAPI** — веб-фреймворк
- **Pydantic** — валидация данных
- **Poetry** — управление зависимостями

## Устранение неполадок

### Частые проблемы

**Ошибка подключения к Ollama:**
```bash
# Убедитесь, что Ollama запущен
ollama serve

# Проверьте статус
ollama list
```

**Ошибка загрузки модели:**
```bash
# Перезагрузите модель
ollama pull qwen2.5:7b

# Проверьте свободное место на диске
df -h
```

**Ошибка ChromaDB:**
```bash
# Очистите базу данных и пересоздайте
rm -rf data/chroma/
python scripts/ingest_chroma.py
```

**Проблемы с памятью:**
- Увеличьте swap файл
- Закройте другие приложения
- Используйте модель меньшего размера

### Логи и отладка

Логи приложения сохраняются в `data/app.log`:
```bash
tail -f data/app.log
```

### Поддержка

При возникновении проблем:
1. Проверьте логи в `data/app.log`
2. Убедитесь, что все зависимости установлены
3. Проверьте требования к системе
4. Создайте issue в репозитории с описанием проблемы

## Лицензия

MIT License
